# What i Did:
- Created a new pipline  called it Ingest Data
- Create a lakehouse  for my  data files called Learn_Lakehouse
- Configured a Copy Data activity to move data from source to destination and used "NYC Taxi - Green" dataset as your data source.
- Set up a managed Delta Lake table named taxi_rides in your lakehouse

# What i learned:

- Pipelines provide a guided, repeatable way to bring data into the lakehouse. Theyâ€™re easier than coding from scratch and can be scheduled later if needed.
- 
